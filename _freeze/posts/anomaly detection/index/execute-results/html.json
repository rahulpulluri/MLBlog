{
  "hash": "f4ffdf39e3937b242e8233bd1147565f",
  "result": {
    "markdown": "---\ntitle: Anomaly/Outlier detection\nauthor: Rahul Pulluri\ndate: '2023-11-24'\nimage: 1_BaOiTGWAoFi-3_-E-rJGdg.webp\n---\n\n![Image Source: <https://miro.medium.com/v2/resize:fit:720/format:webp/1*BaOiTGWAoFi-3_-E-rJGdg.jpeg>](1_BaOiTGWAoFi-3_-E-rJGdg.webp)\n\n## Anomaly/Outlier Detection: An Overview\n\nAnomaly detection, also known as outlier detection, is a process in data analysis where unusual patterns, items, or events in a dataset are identified. These anomalies are often referred to as outliersâ€”data points that deviate significantly from the majority of the data. Anomaly detection is crucial as these outliers can indicate critical incidents, such as bank fraud, structural defects, system faults, or errors in text data.\n\n\n## Key Concepts\n\n### **Anomalies:** \nA data point or a pattern that does not conform to the expected behavior. Anomalies can be:\n\n**Point Anomalies:**  Individual data points that are significantly different from the rest of the data.\n**Contextual Anomalies:** Anomalies that are context-specific. These might not be outliers in a different context.\n**Collective Anomalies:** A group of data points that collectively deviate from the overall data pattern but might not be anomalies when considered individually.\n\n### **Outlier:**\nOften used interchangeably with anomalies, outliers are data points that differ drastically from the rest of the dataset.\n\n## Techniques in Anomaly Detection\nAnomaly detection in machine learning can be approached in various ways:\n\n### **Statistical Methods:**\n\n- Simple statistical metrics like mean, median, standard deviation, and interquartile ranges are used to identify outliers.\n- Methods like Z-score and Grubbs' test can flag data points that deviate from the expected distribution.\n\n### **Machine Learning Methods:**\n\n- **Supervised Learning:** This requires a dataset with labeled anomalies. Algorithms like logistic regression, support vector machines, or neural networks can be trained to recognize and predict anomalies.\n\n- **Unsupervised Learning:** Useful when you don't have labeled data. Algorithms like k-means clustering, DBSCAN, or autoencoders can detect anomalies by understanding the data's inherent structure and distribution.\n\n- **Semi-Supervised Learning:** Involves training on a primarily normal dataset to understand the pattern of normality, against which anomalies can be detected.\n\n\n### **Proximity-Based Methods:**\n\nThese methods identify anomalies based on the distance or similarity between data points. For example, k-nearest neighbors (KNN) can be used to detect points that are far from their neighbors.\n\n### **Density-Based Methods:**\n\nTechniques like Local Outlier Factor (LOF) focus on the density of the area around a data point. Anomalies are typically located in low-density regions.\n\n### **Clustering-Based Methods:**\n\nAlgorithms like K-means or Hierarchical Clustering can group similar data together. Points that do not fit well into any cluster may be considered anomalies.\n\n## Applications of Anomaly Detection\n\n**Fraud Detection:** In banking and finance, detecting unusual transactions that could indicate fraud.\n\n**Intrusion Detection:** In cybersecurity, identifying unusual patterns that could signify a security breach.\n\n**Fault Detection:** In industrial settings, detecting irregularities in machine or system operations to preempt failures.\n\n**Health Monitoring:** In healthcare, identifying unusual patterns in patient data that could indicate medical issues.\n\n**Quality Control:** In manufacturing, detecting products that don't meet quality standards.\n\n\n## Anomaly Detection Method with Weight and Height Dataset\n\n\n\n**Importing libraries and loading data**\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv(\"R:/MLBlog/posts/anomaly detection/weight-height.csv\")\nFEATURE_COLUMNS = ['Height', 'Weight']\nprint(df.shape)\ndf.sample(5).T\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(10000, 3)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3079</th>\n      <th>6246</th>\n      <th>7955</th>\n      <th>1967</th>\n      <th>8314</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Gender</th>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>Height</th>\n      <td>71.053249</td>\n      <td>58.964069</td>\n      <td>66.417472</td>\n      <td>69.16247</td>\n      <td>59.548895</td>\n    </tr>\n    <tr>\n      <th>Weight</th>\n      <td>215.258776</td>\n      <td>91.78555</td>\n      <td>139.74328</td>\n      <td>190.84907</td>\n      <td>118.860323</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Interquartile range (IQR)\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef plot_results(df, df0, method_str=\"IQR\"):\n    # Plotting the data\n    plt.scatter(df['Height'], df['Weight'], label='Data', alpha=0.25)\n    plt.scatter(df0['Height'], df0['Weight'], color='r', alpha=1, label=f'Outliers, {method_str}')\n    plt.xlabel('Height')\n    plt.ylabel('Weight')\n    plt.title(f'Outlier Detection using {method_str}')\n    plt.legend()\n    plt.show();\n    return None\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef detect_outliers_iqr(dataframe, column):\n    '''Uses Interquartile range (IQR) method to detect outliers'''\n    # Calculate the first quartile (Q1)\n    Q1 = dataframe[column].quantile(0.25)\n    # Calculate the third quartile (Q3)\n    Q3 = dataframe[column].quantile(0.75)\n    # Calculate the interquartile range (IQR)\n    IQR = Q3 - Q1\n    # Define the lower and upper bounds for outliers\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    # Find the outliers\n    dataframe[f'outliers_iqr_{column}'] = ((dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)).astype(int)\n    return dataframe\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfor col in ['Weight', 'Height']:\n    df = detect_outliers_iqr(df, col)\ndf0 = df[df['outliers_iqr_Height']+df['outliers_iqr_Weight']>0].copy()\nprint(df0.shape)\nplot_results(df, df0, method_str=\"IQR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(8, 5)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-2.png){width=597 height=449}\n:::\n:::\n\n\n## Isolation forest\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef detect_outliers_isolation_forest(dataframe):\n    # Create an Isolation Forest instance\n    clf = IsolationForest(contamination=0.01, n_estimators=100, bootstrap=False, random_state=42)\n    # Fit the model\n    clf.fit(dataframe[FEATURE_COLUMNS])\n    # Predict outliers\n    outliers = clf.predict(dataframe[FEATURE_COLUMNS])\n    # Create a boolean mask for outliers\n    outliers_mask = outliers == -1\n    # Mark the outliers\n    dataframe[f'outliers_iforest'] = (outliers_mask).astype(int)\n    return dataframe\n\n# Detect outliers using the IF method on column\ndf = detect_outliers_isolation_forest(df)\n\nprint(\"Outliers:\")\n    \n# Plotting the data\ndf0 = df[df['outliers_iforest']>0].copy()\nprint(df0.shape)\nplot_results(df, df0, method_str=\"Isolation Forest\")\ndf.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOutliers:\n(100, 6)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-2.png){width=597 height=449}\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>outliers_iqr_Weight</th>\n      <th>outliers_iqr_Height</th>\n      <th>outliers_iforest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.0000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>66.367560</td>\n      <td>161.440357</td>\n      <td>0.0001</td>\n      <td>0.000800</td>\n      <td>0.010000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.847528</td>\n      <td>32.108439</td>\n      <td>0.0100</td>\n      <td>0.028274</td>\n      <td>0.099504</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>54.263133</td>\n      <td>64.700127</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>63.505620</td>\n      <td>135.818051</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>66.318070</td>\n      <td>161.212928</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>69.174262</td>\n      <td>187.169525</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>78.998742</td>\n      <td>269.989699</td>\n      <td>1.0000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Local Outlier Factor\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef detect_outliers_lof(dataframe):\n    # Create an LOF instance\n    lof = LocalOutlierFactor(n_neighbors=20, contamination='auto')\n    # Fit the model and predict outlier scores\n    outlier_scores = lof.fit_predict(dataframe[FEATURE_COLUMNS])\n    # Create a boolean mask for outliers\n    outliers_mask = outlier_scores == -1\n    # Mark the outliers\n    dataframe[f'outliers_lof'] = (outliers_mask).astype(int)\n    return dataframe\n\n# Detect outliers using the LOF method on\ndf = detect_outliers_lof(df)\n\nprint(\"Outliers:\")\n    \n# Plotting the data\ndf0 = df[df['outliers_lof']+df['outliers_lof']>0].copy()\nprint(df0.shape)\nplot_results(df, df0, method_str=\"LocalOutlierFactor\")\n\ndf.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOutliers:\n(132, 7)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-2.png){width=597 height=449}\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>outliers_iqr_Weight</th>\n      <th>outliers_iqr_Height</th>\n      <th>outliers_iforest</th>\n      <th>outliers_lof</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.0000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>66.367560</td>\n      <td>161.440357</td>\n      <td>0.0001</td>\n      <td>0.000800</td>\n      <td>0.010000</td>\n      <td>0.013200</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.847528</td>\n      <td>32.108439</td>\n      <td>0.0100</td>\n      <td>0.028274</td>\n      <td>0.099504</td>\n      <td>0.114136</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>54.263133</td>\n      <td>64.700127</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>63.505620</td>\n      <td>135.818051</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>66.318070</td>\n      <td>161.212928</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>69.174262</td>\n      <td>187.169525</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>78.998742</td>\n      <td>269.989699</td>\n      <td>1.0000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## One-class SVM\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndef detect_outliers_svm(dataframe):\n    # Create a One-Class SVM instance\n    svm = OneClassSVM(nu=0.01)\n    # Fit the model\n    svm.fit(dataframe[FEATURE_COLUMNS])\n    # Predict outlier scores\n    outlier_scores = svm.decision_function(dataframe[FEATURE_COLUMNS])\n    # Create a boolean mask for outliers\n    outliers_mask = outlier_scores < 0\n    # Mark the outliers\n    dataframe[f'outliers_svm'] = (outliers_mask).astype(int)\n    return dataframe\n\n# Detect outliers using the SVM method\ndf = detect_outliers_svm(df)\n\nprint(\"Outliers:\")\n    \n# Plotting the data\ndf0 = df[df['outliers_svm']>0].copy()\nprint(df0.shape)\nplot_results(df, df0, method_str=\"One-class SVM\")\ndf.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOutliers:\n(101, 8)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-2.png){width=597 height=449}\n:::\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>outliers_iqr_Weight</th>\n      <th>outliers_iqr_Height</th>\n      <th>outliers_iforest</th>\n      <th>outliers_lof</th>\n      <th>outliers_svm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.0000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>66.367560</td>\n      <td>161.440357</td>\n      <td>0.0001</td>\n      <td>0.000800</td>\n      <td>0.010000</td>\n      <td>0.013200</td>\n      <td>0.010100</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.847528</td>\n      <td>32.108439</td>\n      <td>0.0100</td>\n      <td>0.028274</td>\n      <td>0.099504</td>\n      <td>0.114136</td>\n      <td>0.099995</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>54.263133</td>\n      <td>64.700127</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>63.505620</td>\n      <td>135.818051</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>66.318070</td>\n      <td>161.212928</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>69.174262</td>\n      <td>187.169525</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>78.998742</td>\n      <td>269.989699</td>\n      <td>1.0000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Autoencoder\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nclass Autoencoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 2*hidden_dim),\n            nn.ReLU(),\n            nn.Linear(2*hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(hidden_dim, 2*hidden_dim),\n            nn.ReLU(),\n            nn.Linear(2*hidden_dim, input_dim),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nclass OutlierDataset(Dataset):\n    def __init__(self, data):\n        self.data = torch.tensor(data, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\ndef detect_outliers_autoencoder(dataframe, hidden_dim=16, num_epochs=10, batch_size=32):\n    # Convert dataframe to standard scaled numpy array\n    scaler = StandardScaler()\n    data = scaler.fit_transform(dataframe[FEATURE_COLUMNS])\n\n    # Create an outlier dataset\n    dataset = OutlierDataset(data)\n\n    # Split data into training and validation sets\n    val_split = int(0.2 * len(dataset))\n    train_set, val_set = torch.utils.data.random_split(dataset, [len(dataset) - val_split, val_split])\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size)\n\n    # Initialize the autoencoder model\n    input_dim = data.shape[1]\n    model = Autoencoder(input_dim, hidden_dim)\n\n    # Set the loss function and optimizer\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=3e-2, weight_decay=1e-8)\n\n    # Train the autoencoder\n    for epoch in range(num_epochs):\n        train_loss = 0.0\n        val_loss = 0.0\n\n        # Training\n        model.train()\n        for batch in train_loader:\n            # Zero the gradients\n            optimizer.zero_grad()\n            # Forward pass\n            outputs = model(batch)\n            # Compute the reconstruction loss\n            loss = criterion(outputs, batch)\n            # Backward pass and optimization\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * batch.size(0)\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                outputs = model(batch)\n                loss = criterion(outputs, batch)\n                val_loss += loss.item() * batch.size(0)\n\n        train_loss /= len(train_set)\n        val_loss /= len(val_set)\n\n\n        print(f'Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n        \n    # Calculate reconstruction error for each data point\n    reconstructed = model(dataset.data)\n    mse_loss = nn.MSELoss(reduction='none')\n    error = torch.mean(mse_loss(reconstructed, dataset.data), dim=1)\n\n    \n    # Define a threshold for outlier detection\n    threshold = np.percentile(error.detach().numpy(), 99)\n\n    # Create a boolean mask for outliers\n    outliers_mask = (error > threshold)\n\n    # Mark the outliers\n    dataframe[f'outliers_autoenc'] = (outliers_mask)\n    dataframe[f'outliers_autoenc'] = dataframe[f'outliers_autoenc'].astype(int)\n    return dataframe\n\n# Detect outliers using the autoencoder method\ndf = detect_outliers_autoencoder(df)\n\nprint(\"Outliers:\")\n    \n# Plotting the data\ndf0 = df[df['outliers_autoenc']>0].copy()\nprint(df0.shape)\nplot_results(df, df0, method_str=\"One-class Autoencoders\")\n\ndf.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/10: Train Loss: 0.5783, Val Loss: 0.5444\nEpoch 2/10: Train Loss: 0.5579, Val Loss: 0.5471\nEpoch 3/10: Train Loss: 0.5576, Val Loss: 0.5437\nEpoch 4/10: Train Loss: 0.5571, Val Loss: 0.5435\nEpoch 5/10: Train Loss: 0.5575, Val Loss: 0.5440\nEpoch 6/10: Train Loss: 0.5571, Val Loss: 0.5440\nEpoch 7/10: Train Loss: 0.5573, Val Loss: 0.5438\nEpoch 8/10: Train Loss: 0.5572, Val Loss: 0.5436\nEpoch 9/10: Train Loss: 0.5575, Val Loss: 0.5441\nEpoch 10/10: Train Loss: 0.5571, Val Loss: 0.5434\nOutliers:\n(100, 9)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-2.png){width=597 height=449}\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>outliers_iqr_Weight</th>\n      <th>outliers_iqr_Height</th>\n      <th>outliers_iforest</th>\n      <th>outliers_lof</th>\n      <th>outliers_svm</th>\n      <th>outliers_autoenc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.0000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>66.367560</td>\n      <td>161.440357</td>\n      <td>0.0001</td>\n      <td>0.000800</td>\n      <td>0.010000</td>\n      <td>0.013200</td>\n      <td>0.010100</td>\n      <td>0.010000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.847528</td>\n      <td>32.108439</td>\n      <td>0.0100</td>\n      <td>0.028274</td>\n      <td>0.099504</td>\n      <td>0.114136</td>\n      <td>0.099995</td>\n      <td>0.099504</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>54.263133</td>\n      <td>64.700127</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>63.505620</td>\n      <td>135.818051</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>66.318070</td>\n      <td>161.212928</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>69.174262</td>\n      <td>187.169525</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>78.998742</td>\n      <td>269.989699</td>\n      <td>1.0000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}