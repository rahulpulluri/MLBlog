{
  "hash": "516340a5bd568bbfcf14fbd3f289457a",
  "result": {
    "markdown": "---\ntitle: \"Linear Regression\"\nauthor: \"Rahul Pulluri\"\ndate: \"2023-11-26\"\nimage: \"regression.jpg\"\ndescription: \"Linear Regression is a supervised learning algorithm used for modeling the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data.\"\ncategories: [python, code, analysis]\n---\n\n![](linear-regression-visualization.png)\n\n\n## Definition:\n\n- Linear regression is a statistical method used in data science and machine learning for predictive analysis.\n- It establishes a linear relationship between an independent variable (predictor) and a dependent variable (outcome) for prediction.\n- The method is suitable for continuous or numeric variables like sales, salary, age, etc.\n\n## Importance in Various Fields:\n\n- Used in stock market forecasting, portfolio management, scientific analysis, and more.\n- A simple representation is a sloped straight line in a graph, depicting the best fit line for a set of data.\n\n## Benefits of Linear Regression:\n\n- Easy to implement and interpret.\n- Scalable and optimal for online settings due to its computational efficiency.\n\n## Linear Regression Equation:\n\nThe equation Y = m*X + b, where 'm' is the slope and 'b' is the intercept, describes the relationship.\nIn machine learning, it's often expressed as y(x) = p0 + p1 * x, where p0 and p1 are parameters to be determined.\n\n## Types of Linear Regression:\n\n### **Simple Linear Regression:**\n\n**Definition:** Simple Linear Regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables. This method assumes a linear relationship between the dependent variable and the independent variable.\n\n**Equation:** Y = β0 + β1 * X + ε\n\n- Y: Dependent variable\n\n- X: Independent variable\n\n- β0: Intercept of the regression line\n\n- β1: Slope of the regression line\n\n- ε: Error term\n\n**Application:** For example, predicting the price of a house (dependent variable) based on its size (independent variable).\n\n\n## **Multiple Linear Regression:**\n\n**Definition:** Multiple Linear Regression is an extension of simple linear regression and is used to predict the outcome of a dependent variable based on the value of two or more independent variables. This method helps in understanding how changes in independent variables are associated with changes in the dependent variable.\n\n**Equation:** Y = β0 + β1 * X1 + β2 * X2 + ... + βn * Xn + ε\n\n- Y: Dependent variable\n\n- X1, X2, ..., Xn: Independent variables\n\n- β0: Intercept\n\n- β1, β2, ..., βn: Slopes for each independent variable\n\n- ε: Error term\n\n**Application:** Predicting a person's weight based on their height, age, and diet (three independent variables).\n\n## **Logistic Regression:**\n\n**Definition:** Logistic Regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes). It is used for predicting the probability of a binary outcome based on one or more predictor variables.\n\n**Equation:** log(p/(1-p)) = β0 + β1 * X1 + ... + βn * Xn\n\n- p: Probability of the dependent event occurring\n\n- X1, ..., Xn: Predictor variables\n\n- β0: Intercept\n\n- β1, ..., βn: Coefficients for each predictor\n\n**Application:** Determining whether an email is spam or not spam, based on features like the email's content, sender, etc.\n\n## **Ordinal Regression:**\n\n**Definition:** Ordinal Regression is used when the dependent variable is ordinal, meaning it reflects a scale of magnitude. It models the relationship between a set of predictor variables and an ordinal scale dependent variable, where the categories have a natural order, but the intervals between them are not assumed to be equidistant.\n\n**Characteristics:** The categories have a ranked order, but the intervals between the ranks are not necessarily equal.\n\n**Application:** Rating a movie as poor, fair, good, very good, and excellent. Here, the ratings have a natural order but the difference between each category is not quantified.\n\n## **Multinomial Logistic Regression:**\n\n**Definition:** Multinomial Logistic Regression is a classification method that generalizes logistic regression to multiclass problems, i.e., where the dependent variable can have more than two possible nominal (unordered) outcomes. It is used when the outcome involves more than two categories.\n\n**Characteristics:** Similar to logistic regression, but suitable for more than two classes.\n\n**Application:** Predicting the choice of transportation (like car, bus, train, bike) based on factors like distance, cost, and time.\n\n\n## Example: Yearly Amount Spent Prediction\n\n**Import Libraries and Reading Data**\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\ndf = pd.read_csv(\"R:/Blog/posts/linregression/Ecommerce Customers.csv\")\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Email</th>\n      <th>Address</th>\n      <th>Avatar</th>\n      <th>Avg. Session Length</th>\n      <th>Time on App</th>\n      <th>Time on Website</th>\n      <th>Length of Membership</th>\n      <th>Yearly Amount Spent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mstephenson@fernandez.com</td>\n      <td>835 Frank Tunnel\\nWrightmouth, MI 82180-9605</td>\n      <td>Violet</td>\n      <td>34.50</td>\n      <td>12.66</td>\n      <td>39.58</td>\n      <td>4.08</td>\n      <td>587.95</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hduke@hotmail.com</td>\n      <td>4547 Archer Common\\nDiazchester, CA 06566-8576</td>\n      <td>DarkGreen</td>\n      <td>31.93</td>\n      <td>11.11</td>\n      <td>37.27</td>\n      <td>2.66</td>\n      <td>392.20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pallen@yahoo.com</td>\n      <td>24645 Valerie Unions Suite 582\\nCobbborough, D...</td>\n      <td>Bisque</td>\n      <td>33.00</td>\n      <td>11.33</td>\n      <td>37.11</td>\n      <td>4.10</td>\n      <td>487.55</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>riverarebecca@gmail.com</td>\n      <td>1414 David Throughway\\nPort Jason, OH 22070-1220</td>\n      <td>SaddleBrown</td>\n      <td>34.31</td>\n      <td>13.72</td>\n      <td>36.72</td>\n      <td>3.12</td>\n      <td>581.85</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mstephens@davidson-herman.com</td>\n      <td>14023 Rodriguez Passage\\nPort Jacobville, PR 3...</td>\n      <td>MediumAquaMarine</td>\n      <td>33.33</td>\n      <td>12.80</td>\n      <td>37.54</td>\n      <td>4.45</td>\n      <td>599.41</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe variables to be used in the data were determined.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf = df.drop(['Email',\"Address\",\"Avatar\"], axis=1) \n```\n:::\n\n\n**Advanced Functional Exploratory Data Analysis**\n\nGeneral structure of the data is analyzed\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef check_df(dataframe, head=5):\n    print(\"##################### Columns #####################\")\n    print(dataframe.columns)\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.describe([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ncheck_df(df)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n##################### Columns #####################\nIndex(['Avg. Session Length', 'Time on App', 'Time on Website',\n       'Length of Membership', 'Yearly Amount Spent'],\n      dtype='object')\n##################### Shape #####################\n(500, 5)\n##################### Types #####################\nAvg. Session Length     float64\nTime on App             float64\nTime on Website         float64\nLength of Membership    float64\nYearly Amount Spent     float64\ndtype: object\n##################### Head #####################\n   Avg. Session Length  Time on App  Time on Website  Length of Membership  \\\n0                34.50        12.66            39.58                  4.08   \n1                31.93        11.11            37.27                  2.66   \n2                33.00        11.33            37.11                  4.10   \n3                34.31        13.72            36.72                  3.12   \n4                33.33        12.80            37.54                  4.45   \n\n   Yearly Amount Spent  \n0               587.95  \n1               392.20  \n2               487.55  \n3               581.85  \n4               599.41  \n##################### Tail #####################\n     Avg. Session Length  Time on App  Time on Website  Length of Membership  \\\n495                33.24        13.57            36.42                  3.75   \n496                34.70        11.70            37.19                  3.58   \n497                32.65        11.50            38.33                  4.96   \n498                33.32        12.39            36.84                  2.34   \n499                33.72        12.42            35.77                  2.74   \n\n     Yearly Amount Spent  \n495               573.85  \n496               529.05  \n497               551.62  \n498               456.47  \n499               497.78  \n##################### NA #####################\nAvg. Session Length     0\nTime on App             0\nTime on Website         0\nLength of Membership    0\nYearly Amount Spent     0\ndtype: int64\n##################### Quantiles #####################\n                      count   mean   std    min     0%     5%    50%    95%  \\\nAvg. Session Length  500.00  33.05  0.99  29.53  29.53  31.45  33.08  34.59   \nTime on App          500.00  12.05  0.99   8.51   8.51  10.53  11.98  13.67   \nTime on Website      500.00  37.06  1.01  33.91  33.91  35.46  37.07  38.78   \nLength of Membership 500.00   3.53  1.00   0.27   0.27   1.81   3.53   5.08   \nYearly Amount Spent  500.00 499.31 79.31 256.67 256.67 376.29 498.89 628.15   \n\n                        99%   100%    max  \nAvg. Session Length   35.43  36.14  36.14  \nTime on App           14.22  15.13  15.13  \nTime on Website       39.25  40.01  40.01  \nLength of Membership   5.84   6.92   6.92  \nYearly Amount Spent  701.00 765.52 765.52  \n```\n:::\n:::\n\n\nA scatterplot to observe the relationship between the variables was created.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nsns.pairplot(df, kind = \"reg\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=1179 height=1179}\n:::\n:::\n\n\n**Analysis of Variable Types**\n\nIt is necessary to determine the types of variables. Thus, we can determine the types of the variables and make them suitable for the model.\n\nIt gives the names of the numeric, categorical but cardinal variables in the data set.\n\ncat_cols: Categorical variable list\n\nnum_cols: Numeric variable list\n\ncat_but_car: Categorical but cardinal variable list\n\nThe function named grab_col_names helps to determine the types of variables.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nObservations: 500\nVariables: 5\ncat_cols: 0\nnum_cols: 5\ncat_but_car: 0\nnum_but_cat: 0\n```\n:::\n:::\n\n\n**Outlier Analysis**\n\nValues that go far beyond the general trend in the data are called outliers. Especially in linear methods, the effects of outliers are more severe.Outliers cause bias in the data set.For all these reasons, it needs to be analyzed.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef outlier_thresholds(dataframe, col_name, q1=0.10, q3=0.90):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\nfor col in num_cols:\n    print(col, check_outlier(df, col))\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAvg. Session Length False\nTime on App False\nTime on Website False\nLength of Membership False\nYearly Amount Spent False\n```\n:::\n:::\n\n\nAvg. Session Length False\nTime on App False\nTime on Website False\nLength of Membership False\nYearly Amount Spent False\n\n**Analysis Of Missing Values**\n\nMissing values may cause problems while setting up the model. It must be detected and necessary actions must be taken.\n\nNo missing values were found for the relevant data.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns\n\nmissing_values_table(df)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEmpty DataFrame\nColumns: [n_miss, ratio]\nIndex: []\n```\n:::\n:::\n\n\nEmpty DataFrame\nColumns: [n_miss, ratio]\nIndex: []\n\n**Correlation Analysis**\n\nValues with high correlation affect the target variable to a similar extent. Therefore, we can eliminate one of the variables with high correlation between two variables and use the other.\n\nWhen the data was examined, no variable with a high correlation of more than 90% was found.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndef high_correlated_cols(dataframe, plot=False, corr_th=0.90):\n    corr = dataframe.corr()\n    cor_matrix = corr.abs()\n    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))\n    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n    if plot:\n        import seaborn as sns\n        import matplotlib.pyplot as plt\n        sns.set(rc={'figure.figsize': (10, 5)})\n        sns.heatmap(corr, cmap=\"RdBu\", annot=True)\n        plt.show(block=True)\n    return drop_list\n\n\nhigh_correlated_cols(df,plot=True)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=862 height=553}\n:::\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\n[]\n```\n:::\n:::\n\n\n## LINEAR REGRESSION\n\n![](linear.png)\n\nLinear regression models the relationship between dependent and independent variable/variables linearly.\n\nIn order to create the model, dependent and independent variables were defined.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nX = df.drop('Yearly Amount Spent', axis=1) \n\ny = df[[\"Yearly Amount Spent\"]]\n```\n:::\n\n\n**Building the Model**\n\nBuilding the Model\nA train and test set by dividing the data into two is created . By training the model with one part and testing the model with the other part, it can be determined how successful the model is.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n\nreg_model = LinearRegression().fit(X_train, y_train)\n\n# constant (b - bias)\nprint(reg_model.intercept_)\n\n# coefficients (w - weights)\nprint(reg_model.coef_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[-1047.73920526]\n[[25.78854257 38.85150472  0.25638467 61.49204989]]\n```\n:::\n:::\n\n\nPrediction of dependent variable\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ny_pred = reg_model.predict(X_test)\n```\n:::\n\n\n## Evaluating Forecast Success\n!(rmse.png)\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nnp.sqrt(mean_squared_error(y_test, y_pred))\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\n8.84848631350032\n```\n:::\n:::\n\n\nThe ratio of independent variables description of dependent variable\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nreg_model.score(X_test, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\n0.9892888134002329\n```\n:::\n:::\n\n\n## Visualization of the Model\n\nFinally, the actual values corresponding to the predicted values of the model are shown in the graph.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ny_pred = pd.DataFrame(y_pred)\ny_test = y_test.reset_index(drop=True)\ndf_ = pd.concat([y_test,y_pred], axis=1)\ndf_.columns = [\"y_test\",\"y_pred\"]\nplt.figure(figsize=(15,10))\nplt.plot(df_)\nplt.legend([\"ACTUAL VALUES\" , \"MODEL PREDICTION\"])\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```\n<matplotlib.legend.Legend at 0x178df7dcdc0>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){width=1172 height=785}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}