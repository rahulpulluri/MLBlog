<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rahul Pulluri">
<meta name="dcterms.date" content="2023-11-19">

<title>Machine Learning - Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Machine Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Rahul Pulluri</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/tpriya14/MLBlog" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/tspriya14" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Classification</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Rahul Pulluri </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 19, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><img src="Classification_main.jpeg" class="img-fluid"></p>
<section id="definition-and-overview-of-classification" class="level2">
<h2 class="anchored" data-anchor-id="definition-and-overview-of-classification">Definition and Overview of Classification</h2>
<p>Classification in machine learning and statistics is a supervised learning approach where the objective is to categorize data into predefined classes. In simpler terms, it involves deciding which category or class a new observation belongs to, based on a training set of data containing observations whose category membership is known.</p>
</section>
<section id="key-components" class="level2">
<h2 class="anchored" data-anchor-id="key-components">Key Components</h2>
<p><strong>Classes or Categories:</strong> These are the distinct groups or categories that data points are classified into. For instance, in a binary classification, there are two classes, while in multi-class classification, there could be three or more.</p>
<p><strong>Features:</strong> These are individual independent variables that act as the input for the process. Each feature contributes to determining the output class.</p>
<p><strong>Labels:</strong> In the training dataset, each data point is tagged with the correct label, which the algorithm then learns to predict.</p>
</section>
<section id="how-classification-works" class="level2">
<h2 class="anchored" data-anchor-id="how-classification-works">How Classification Works</h2>
<p><strong>Training Phase:</strong> The algorithm is trained on a labeled dataset, where it learns the relationship between features and the corresponding class labels.</p>
<p><strong>Model Building:</strong> The algorithm creates a model that maps inputs (features) to desired outputs (labels). This model represents the learned patterns from the data.</p>
<p><strong>Testing and Prediction:</strong> The trained model is then used to predict the class labels of new, unseen data. The performance of the model is typically evaluated using metrics like accuracy, precision, recall, and F1 score.</p>
</section>
<section id="types-of-classification" class="level2">
<h2 class="anchored" data-anchor-id="types-of-classification">Types of Classification</h2>
<p><strong>Binary Classification:</strong> Involves two classes. Common examples include spam detection (spam or not spam) and medical diagnoses (sick or healthy).</p>
<p><strong>Multiclass Classification:</strong> Involves more than two classes, but each instance is assigned to only one class. An example would be classifying types of fruits.</p>
<p><strong>Multilabel Classification:</strong> Each instance may be assigned to multiple classes. For example, a news article might be categorized into multiple genres like sports, politics, and finance.</p>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<p><strong>Medical Diagnosis:</strong> Identifying diseases based on symptoms and test results.</p>
<p><strong>Spam Filtering:</strong> Categorizing emails as spam or non-spam.</p>
<p><strong>Sentiment Analysis:</strong> Classifying the sentiment of text data (positive, negative, neutral).</p>
<p><strong>Image Recognition:</strong> Categorizing images into various classes like animals, objects, etc. Credit Scoring: Assessing creditworthiness as high-risk or low-risk.</p>
<p>Once trained, the algorithm can classify new, unseen data by assessing its similarity to the patterns it has learned. It predicts the likelihood of the new data point falling into one of the predefined categories. This process is akin to your email provider recognizing whether an incoming email is spam or not based on past experiences.</p>
</section>
<section id="classification-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="classification-algorithms">Classification Algorithms</h2>
<section id="logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression"><strong>Logistic Regression:</strong></h3>
<p>Overview: Logistic Regression is used for binary classification problems. It models the probability that each input belongs to a particular category. Mechanism: This algorithm uses a logistic function to squeeze the output of a linear equation between 0 and 1. The result is the probability that the given input point belongs to a certain class.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="82109Webp.net-resize.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Image Source: <a href="https://editor.analyticsvidhya.com/uploads/82109Webp.net-resize.jpg" class="uri">https://editor.analyticsvidhya.com/uploads/82109Webp.net-resize.jpg</a></figcaption>
</figure>
</div>
<p>Pros: Simple and efficient. Provides a probability score for observations. Low variance, avoiding overfitting.</p>
<p>Cons: Struggles with non-linear data. Assumes no missing values and that predictors are independent.</p>
<p>Applications: Commonly used in fields like credit scoring, medical fields for disease diagnosis, and predictive analytics.</p>
</section>
<section id="naive-bayes" class="level3">
<h3 class="anchored" data-anchor-id="naive-bayes"><strong>Naive Bayes:</strong></h3>
<p>Overview: Based on Bayes’ Theorem, it assumes independence among predictors. Mechanism: It calculates the probability of each class and the conditional probability of each class given each input value. These probabilities are then used to classify the data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bayes_rule-300x172-300x172-111664.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Image Source: <a href="https://av-eks-blogoptimized.s3.amazonaws.com/Bayes_rule-300x172-300x172-111664.png" class="uri">https://av-eks-blogoptimized.s3.amazonaws.com/Bayes_rule-300x172-300x172-111664.png</a></figcaption>
</figure>
</div>
<p>Pros: Fast and efficient. Performs well with a smaller amount of data. Handles multi-class prediction problems well.</p>
<p>Cons: The assumption of independent features is often unrealistic. Can be outperformed by more complex models.</p>
<p>Applications: Widely used in spam filtering, text analysis, and sentiment analysis.</p>
</section>
<section id="k-nearest-neighbors-knn" class="level3">
<h3 class="anchored" data-anchor-id="k-nearest-neighbors-knn"><strong>K-Nearest Neighbors (KNN):</strong></h3>
<p>Overview: A non-parametric method used for classification and regression. Mechanism: Classifies data based on how its neighbors are classified. It finds the K nearest points to the new data point and classifies it based on the majority class of these points.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="k-nearest-neighbor-algorithm-for-machine-learning2.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Image Source: <a href="https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png" class="uri">https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png</a></figcaption>
</figure>
</div>
<p>Pros: Simple and intuitive. No need to build a model or tune parameters. Flexible to feature/distance choices.</p>
<p>Cons: Slows significantly as data size increases. Sensitive to irrelevant or redundant features.</p>
<p>Applications: Used in recommendation systems, image recognition, and more.</p>
</section>
<section id="support-vector-machine-svm" class="level3">
<h3 class="anchored" data-anchor-id="support-vector-machine-svm"><strong>Support Vector Machine (SVM):</strong></h3>
<p>Overview: Effective in high dimensional spaces and best suited for binary classification. Mechanism: Constructs a hyperplane in a multidimensional space to separate different classes. SVM finds the best margin (distance between the line and the support vectors) to separate the classes.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="support-vector-machine-algorithm5.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Image Source: <a href="https://static.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm5.png" class="uri">https://static.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm5.png</a></figcaption>
</figure>
</div>
<p>Pros: Effective in high-dimensional spaces. Uses a subset of training points (support vectors), so it’s memory efficient.</p>
<p>Cons: Not suitable for larger datasets. Does not perform well with noisy data.</p>
<p>Applications: Used in face detection, text and hypertext categorization, classification of images.</p>
</section>
<section id="decision-tree" class="level3">
<h3 class="anchored" data-anchor-id="decision-tree"><strong>Decision Tree:</strong></h3>
<p>Overview: A tree-structure algorithm, where each node represents a feature, each branch a decision rule, and each leaf a class. Mechanism: Splits the data into subsets based on feature values. This process is repeated recursively, resulting in a tree with decision nodes and leaf nodes.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dig10.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Image Source: <a href="https://lh4.googleusercontent.com/v9UQUwaQTAXVH90b-Ugyw2_61_uErfYvTBtG-RNRNB_eHUFq9AmAN_2IOdfOETnbXImnQVN-wPC7_YzDgf7urCeyhyx5UZmuSwV8BVsV8VnHxl1KtgpuxDifJ4pLE23ooYXLlnc" class="uri">https://lh4.googleusercontent.com/v9UQUwaQTAXVH90b-Ugyw2_61_uErfYvTBtG-RNRNB_eHUFq9AmAN_2IOdfOETnbXImnQVN-wPC7_YzDgf7urCeyhyx5UZmuSwV8BVsV8VnHxl1KtgpuxDifJ4pLE23ooYXLlnc</a></figcaption>
</figure>
</div>
<p>Pros: Easy to interpret and explain. Requires little data preparation. Can handle both numerical and categorical data.</p>
<p>Cons: Prone to overfitting, especially with complex trees. Small changes in data can lead to a different tree.</p>
<p>Applications: Used in customer segmentation, fraud detection, and risk assessment.</p>
</section>
</section>
<section id="example-credit-card-fraud-detection" class="level2">
<h2 class="anchored" data-anchor-id="example-credit-card-fraud-detection">Example: Credit Card Fraud Detection</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Importing librairies</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Scikit-learn library: For SVM</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Matplotlib library to plot the charts</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.mlab <span class="im">as</span> mlab</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Library for the statistic data vizualisation</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Data recuperation</strong></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'R:/Blog/posts/classification/creditcard.csv'</span>) <span class="co"># Reading the file .csv</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data) <span class="co"># Converting data to Panda DataFrame</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Data Visualization</strong></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data) <span class="co"># Converting data to Panda DataFrame</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.describe() <span class="co"># Description of statistic features (Sum, Average, Variance, minimum, 1st quartile, 2nd quartile, 3rd Quartile and Maximum)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Time</th>
<th data-quarto-table-cell-role="th">V1</th>
<th data-quarto-table-cell-role="th">V2</th>
<th data-quarto-table-cell-role="th">V3</th>
<th data-quarto-table-cell-role="th">V4</th>
<th data-quarto-table-cell-role="th">V5</th>
<th data-quarto-table-cell-role="th">V6</th>
<th data-quarto-table-cell-role="th">V7</th>
<th data-quarto-table-cell-role="th">V8</th>
<th data-quarto-table-cell-role="th">V9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">V21</th>
<th data-quarto-table-cell-role="th">V22</th>
<th data-quarto-table-cell-role="th">V23</th>
<th data-quarto-table-cell-role="th">V24</th>
<th data-quarto-table-cell-role="th">V25</th>
<th data-quarto-table-cell-role="th">V26</th>
<th data-quarto-table-cell-role="th">V27</th>
<th data-quarto-table-cell-role="th">V28</th>
<th data-quarto-table-cell-role="th">Amount</th>
<th data-quarto-table-cell-role="th">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>284807.000000</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>...</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>2.848070e+05</td>
<td>284807.000000</td>
<td>284807.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>94813.859575</td>
<td>1.168375e-15</td>
<td>3.416908e-16</td>
<td>-1.379537e-15</td>
<td>2.074095e-15</td>
<td>9.604066e-16</td>
<td>1.487313e-15</td>
<td>-5.556467e-16</td>
<td>1.213481e-16</td>
<td>-2.406331e-15</td>
<td>...</td>
<td>1.654067e-16</td>
<td>-3.568593e-16</td>
<td>2.578648e-16</td>
<td>4.473266e-15</td>
<td>5.340915e-16</td>
<td>1.683437e-15</td>
<td>-3.660091e-16</td>
<td>-1.227390e-16</td>
<td>88.349619</td>
<td>0.001727</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>47488.145955</td>
<td>1.958696e+00</td>
<td>1.651309e+00</td>
<td>1.516255e+00</td>
<td>1.415869e+00</td>
<td>1.380247e+00</td>
<td>1.332271e+00</td>
<td>1.237094e+00</td>
<td>1.194353e+00</td>
<td>1.098632e+00</td>
<td>...</td>
<td>7.345240e-01</td>
<td>7.257016e-01</td>
<td>6.244603e-01</td>
<td>6.056471e-01</td>
<td>5.212781e-01</td>
<td>4.822270e-01</td>
<td>4.036325e-01</td>
<td>3.300833e-01</td>
<td>250.120109</td>
<td>0.041527</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>0.000000</td>
<td>-5.640751e+01</td>
<td>-7.271573e+01</td>
<td>-4.832559e+01</td>
<td>-5.683171e+00</td>
<td>-1.137433e+02</td>
<td>-2.616051e+01</td>
<td>-4.355724e+01</td>
<td>-7.321672e+01</td>
<td>-1.343407e+01</td>
<td>...</td>
<td>-3.483038e+01</td>
<td>-1.093314e+01</td>
<td>-4.480774e+01</td>
<td>-2.836627e+00</td>
<td>-1.029540e+01</td>
<td>-2.604551e+00</td>
<td>-2.256568e+01</td>
<td>-1.543008e+01</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>54201.500000</td>
<td>-9.203734e-01</td>
<td>-5.985499e-01</td>
<td>-8.903648e-01</td>
<td>-8.486401e-01</td>
<td>-6.915971e-01</td>
<td>-7.682956e-01</td>
<td>-5.540759e-01</td>
<td>-2.086297e-01</td>
<td>-6.430976e-01</td>
<td>...</td>
<td>-2.283949e-01</td>
<td>-5.423504e-01</td>
<td>-1.618463e-01</td>
<td>-3.545861e-01</td>
<td>-3.171451e-01</td>
<td>-3.269839e-01</td>
<td>-7.083953e-02</td>
<td>-5.295979e-02</td>
<td>5.600000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>84692.000000</td>
<td>1.810880e-02</td>
<td>6.548556e-02</td>
<td>1.798463e-01</td>
<td>-1.984653e-02</td>
<td>-5.433583e-02</td>
<td>-2.741871e-01</td>
<td>4.010308e-02</td>
<td>2.235804e-02</td>
<td>-5.142873e-02</td>
<td>...</td>
<td>-2.945017e-02</td>
<td>6.781943e-03</td>
<td>-1.119293e-02</td>
<td>4.097606e-02</td>
<td>1.659350e-02</td>
<td>-5.213911e-02</td>
<td>1.342146e-03</td>
<td>1.124383e-02</td>
<td>22.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>139320.500000</td>
<td>1.315642e+00</td>
<td>8.037239e-01</td>
<td>1.027196e+00</td>
<td>7.433413e-01</td>
<td>6.119264e-01</td>
<td>3.985649e-01</td>
<td>5.704361e-01</td>
<td>3.273459e-01</td>
<td>5.971390e-01</td>
<td>...</td>
<td>1.863772e-01</td>
<td>5.285536e-01</td>
<td>1.476421e-01</td>
<td>4.395266e-01</td>
<td>3.507156e-01</td>
<td>2.409522e-01</td>
<td>9.104512e-02</td>
<td>7.827995e-02</td>
<td>77.165000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>172792.000000</td>
<td>2.454930e+00</td>
<td>2.205773e+01</td>
<td>9.382558e+00</td>
<td>1.687534e+01</td>
<td>3.480167e+01</td>
<td>7.330163e+01</td>
<td>1.205895e+02</td>
<td>2.000721e+01</td>
<td>1.559499e+01</td>
<td>...</td>
<td>2.720284e+01</td>
<td>1.050309e+01</td>
<td>2.252841e+01</td>
<td>4.584549e+00</td>
<td>7.519589e+00</td>
<td>3.517346e+00</td>
<td>3.161220e+01</td>
<td>3.384781e+01</td>
<td>25691.160000</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

<p>8 rows × 31 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df_fraud <span class="op">=</span> df[df[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">1</span>] <span class="co"># Recovery of fraud data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_fraud[<span class="st">'Time'</span>], df_fraud[<span class="st">'Amount'</span>]) <span class="co"># Display fraud amounts according to their time</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Scratter plot amount fraud'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Amount'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="dv">0</span>,<span class="dv">175000</span>])</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="dv">0</span>,<span class="dv">2500</span>])</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-6-output-1.png" width="1248" height="864"></p>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>nb_big_fraud <span class="op">=</span> df_fraud[df_fraud[<span class="st">'Amount'</span>] <span class="op">&gt;</span> <span class="dv">1000</span>].shape[<span class="dv">0</span>] <span class="co"># Recovery of frauds over 1000</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'There are only '</span><span class="op">+</span> <span class="bu">str</span>(nb_big_fraud) <span class="op">+</span> <span class="st">' frauds where the amount was bigger than 1000 over '</span> <span class="op">+</span> <span class="bu">str</span>(df_fraud.shape[<span class="dv">0</span>]) <span class="op">+</span> <span class="st">' frauds'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>There are only 9 frauds where the amount was bigger than 1000 over 492 frauds</code></pre>
</div>
</div>
<p>There are only 9 frauds where the amount was bigger than 1000 over 492 frauds</p>
<ul>
<li>Unbalanced data</li>
</ul>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>number_fraud <span class="op">=</span> <span class="bu">len</span>(data[data.Class <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>number_no_fraud <span class="op">=</span> <span class="bu">len</span>(data[data.Class <span class="op">==</span> <span class="dv">0</span>])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'There are only '</span><span class="op">+</span> <span class="bu">str</span>(number_fraud) <span class="op">+</span> <span class="st">' frauds in the original dataset, even though there are '</span> <span class="op">+</span> <span class="bu">str</span>(number_no_fraud) <span class="op">+</span><span class="st">' no frauds in the dataset.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>There are only 492 frauds in the original dataset, even though there are 284315 no frauds in the dataset.</code></pre>
</div>
</div>
<p>There are only 492 frauds in the original dataset, even though there are 284315 no frauds in the dataset.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy of the classifier then would be : "</span><span class="op">+</span> <span class="bu">str</span>((<span class="dv">284315</span><span class="op">-</span><span class="dv">492</span>)<span class="op">/</span><span class="dv">284315</span>)<span class="op">+</span> <span class="st">" which is the number of good classification over the number of tuple to classify"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The accuracy of the classifier then would be : 0.998269524998681 which is the number of good classification over the number of tuple to classify</code></pre>
</div>
</div>
<p><strong>Correlation of features</strong></p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>df_corr <span class="op">=</span> df.corr() <span class="co"># Calculation of the correlation coefficients in pairs, with the default method:</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Pearson, Standard Correlation Coefficient</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>seaborn.heatmap(df_corr, cmap<span class="op">=</span><span class="st">"YlGnBu"</span>) <span class="co"># Displaying the Heatmap</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>seaborn.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="dv">2</span>,style<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Heatmap correlation'</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-11-output-1.png" width="1161" height="875"></p>
</div>
</div>
<p>As we can notice, most of the features are not correlated with each other. This corroborates the fact that a PCA was previously performed on the data.</p>
<p>What can generally be done on a massive dataset is a dimension reduction. By picking th emost important dimensions, there is a possiblity of explaining most of the problem, thus gaining a considerable amount of time while preventing the accuracy to drop too much.</p>
<p>However in this case given the fact that a PCA was previously performed, if the dimension reduction is effective then the PCA wasn’t computed in the most effective way. Another way to put it is that no dimension reduction should be computed on a dataset on which a PCA was computed correctly.</p>
<p><strong>Correlation of features</strong></p>
<p>OVERSAMPLING</p>
<p>One way to do oversampling is to replicate the under-represented class tuples until we attain a correct proportion between the class</p>
<p>However as we haven’t infinite time nor the patience, we are going to run the classifier with the undersampled training data (for those using the undersampling principle if results are really bad just rerun the training dataset definition)</p>
<p>UNDERSAMPLING</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We seperate ours data in two groups : a train dataset and a test dataset</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># First we build our train dataset</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>df_train_all <span class="op">=</span> df[<span class="dv">0</span>:<span class="dv">150000</span>] <span class="co"># We cut in two the original dataset</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>df_train_1 <span class="op">=</span> df_train_all[df_train_all[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">1</span>] <span class="co"># We seperate the data which are the frauds and the no frauds</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>df_train_0 <span class="op">=</span> df_train_all[df_train_all[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'In this dataset, we have '</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">len</span>(df_train_1)) <span class="op">+</span><span class="st">" frauds so we need to take a similar number of non-fraud"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>df_sample<span class="op">=</span>df_train_0.sample(<span class="dv">300</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>combined_df <span class="op">=</span> pd.concat([df_train_1, df_sample], ignore_index<span class="op">=</span><span class="va">True</span>) <span class="co"># We gather the frauds with the no frauds. </span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>combined_df <span class="op">=</span> combined_df.sample(frac<span class="op">=</span><span class="dv">1</span>) <span class="co"># Then we mix our dataset</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>In this dataset, we have 293 frauds so we need to take a similar number of non-fraud</code></pre>
</div>
</div>
<p>In this dataset, we have 293 frauds so we need to take a similar number of non-fraud</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> combined_df.drop([<span class="st">'Time'</span>, <span class="st">'Class'</span>], axis<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Drop the features "Time" (useless) and "Class" (label)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> combined_df[<span class="st">'Class'</span>]  <span class="co"># Create the label</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.asarray(X_train)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.asarray(y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">############################## with all the test dataset to see if the model learn correctly ##################</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df_test_all <span class="op">=</span> df[<span class="dv">150000</span>:]</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>X_test_all <span class="op">=</span> df_test_all.drop([<span class="st">'Time'</span>, <span class="st">'Class'</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>y_test_all <span class="op">=</span> df_test_all[<span class="st">'Class'</span>]</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>X_test_all <span class="op">=</span> np.asarray(X_test_all)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Confusion Matrix</strong></p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>class_names<span class="op">=</span>np.array([<span class="st">'0'</span>,<span class="st">'1'</span>]) <span class="co"># Binary label, Class = 1 (fraud) and Class = 0 (no fraud)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to plot the confusion Matrix</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(cm, classes,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                          title<span class="op">=</span><span class="st">'Confusion matrix'</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                          cmap<span class="op">=</span>plt.cm.Blues):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    plt.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span>cmap)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    tick_marks <span class="op">=</span> np.arange(<span class="bu">len</span>(classes))</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    plt.xticks(tick_marks, classes, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    plt.yticks(tick_marks, classes)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    fmt <span class="op">=</span> <span class="st">'d'</span> </span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="fl">2.</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, j <span class="kw">in</span> itertools.product(<span class="bu">range</span>(cm.shape[<span class="dv">0</span>]), <span class="bu">range</span>(cm.shape[<span class="dv">1</span>])):</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, <span class="bu">format</span>(cm[i, j], fmt),</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>                 horizontalalignment<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">"white"</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'True label'</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Predicted label'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Model Selection</strong></p>
<p>So now, we’ll use a SVM model classifier, with the scikit-learn library.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>classifier <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'linear'</span>) <span class="co"># We set a SVM classifier, the default SVM Classifier (Kernel = Radial Basis Function)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>classifier.fit(X_train, y_train) <span class="co"># Then we train our model, with our balanced data train.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(kernel='linear')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked=""><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(kernel='linear')</pre></div></div></div></div></div>
</div>
</div>
<p><strong>Testing the model</strong></p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>prediction_SVM_all <span class="op">=</span> classifier.predict(X_test_all) <span class="co">#And finally, we predict our data test.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_all, prediction_SVM_all)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(cm,class_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-20-output-1.png" width="573" height="464"></p>
</div>
</div>
<p>In this case we are gonna try to minimize the number of errors in our prediction results. Errors are on the anti-diagonal of the confusion matrix. But we can infer that being wrong about an actual fraud is far worse than being wrong about a non-fraud transaction.</p>
<p>That is why using the accuracy as only classification criterion could be considered unthoughtful. During the remaining part of this study our criterion will consider precision on the real fraud 4 times more important than the general accuracy. Even though the final tested result is accuracy.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Our criterion give a result of '</span> </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>      <span class="op">+</span> <span class="bu">str</span>( ( (cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>])) <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>])) <span class="op">/</span> <span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Our criterion give a result of 0.9170704904644433</code></pre>
</div>
</div>
<p>Our criterion give a result of 0.905383035408</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'We have detected '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">+</span> <span class="st">' frauds / '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>]) <span class="op">+</span> <span class="st">' total frauds.'</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">So, the probability to detect a fraud is '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>])))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"the accuracy is : "</span><span class="op">+</span><span class="bu">str</span>((cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>]))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>We have detected 181 frauds / 199 total frauds.

So, the probability to detect a fraud is 0.9095477386934674
the accuracy is : 0.9471614975483469</code></pre>
</div>
</div>
<p>We have detected 177 frauds / 199 total frauds.</p>
<p>So, the probability to detect a fraud is 0.889447236181 the accuracy is : 0.969126232317</p>
<p><strong>Models Rank</strong></p>
<p>There is a need to compute the fit method again, as the dimension of the tuples to predict went from 29 to 10 because of the dimension reduction</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a simple feature ranking function (you can customize this)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rank_features(data):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement your feature ranking logic here</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    ranked_features <span class="op">=</span> data  <span class="co"># Replace this with your actual feature ranking code</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ranked_features</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can use the rank_features function</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>X_train_rank <span class="op">=</span> rank_features(X_train)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>X_test_all_rank <span class="op">=</span> rank_features(X_test_all)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>prediction_SVM <span class="op">=</span> classifier.predict(X_test_all_rank)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_all, prediction_SVM)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(cm,class_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-25-output-1.png" width="573" height="464"></p>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Our criterion give a result of '</span> </span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>      <span class="op">+</span> <span class="bu">str</span>( ( (cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>])) <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>])) <span class="op">/</span> <span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Our criterion give a result of 0.9170704904644433</code></pre>
</div>
</div>
<p>Our criterion give a result of 0.912995958898</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'We have detected '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">+</span> <span class="st">' frauds / '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>]) <span class="op">+</span> <span class="st">' total frauds.'</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">So, the probability to detect a fraud is '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>])))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"the accuracy is : "</span><span class="op">+</span><span class="bu">str</span>((cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>]))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>We have detected 181 frauds / 199 total frauds.

So, the probability to detect a fraud is 0.9095477386934674
the accuracy is : 0.9471614975483469</code></pre>
</div>
</div>
<p>We have detected 179 frauds / 199 total frauds.</p>
<p>So, the probability to detect a fraud is 0.899497487437 the accuracy is : 0.966989844741</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb35" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Classification"</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Rahul Pulluri"</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-11-19"</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "classification_main.jpeg"</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="al">![](Classification_main.jpeg)</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## Definition and Overview of Classification</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>Classification in machine learning and statistics is a supervised learning approach where the objective is to categorize data into predefined classes. In simpler terms, it involves deciding which category or class a new observation belongs to, based on a training set of data containing observations whose category membership is known.</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key Components</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>**Classes or Categories:** These are the distinct groups or categories that data points are classified into. For instance, in a binary classification, there are two classes, while in multi-class classification, there could be three or more.</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>**Features:** These are individual independent variables that act as the input for the process. Each feature contributes to determining the output class.</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>**Labels:** In the training dataset, each data point is tagged with the correct label, which the algorithm then learns to predict.</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## How Classification Works</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>**Training Phase:** The algorithm is trained on a labeled dataset, where it learns the relationship between features and the corresponding class labels.</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>**Model Building:** The algorithm creates a model that maps inputs (features) to desired outputs (labels). This model represents the learned patterns from the data.</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>**Testing and Prediction:** The trained model is then used to predict the class labels of new, unseen data. The performance of the model is typically evaluated using metrics like accuracy, precision, recall, and F1 score.</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a><span class="fu">## Types of Classification</span></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>**Binary Classification:** Involves two classes. Common examples include spam detection (spam or not spam) and medical diagnoses (sick or healthy).</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>**Multiclass Classification:** Involves more than two classes, but each instance is assigned to only one class. An example would be classifying types of fruits.</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>**Multilabel Classification:** Each instance may be assigned to multiple classes. For example, a news article might be categorized into multiple genres like sports, politics, and finance.</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a><span class="fu">## Applications</span></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>**Medical Diagnosis:** Identifying diseases based on symptoms and test results.</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>**Spam Filtering:** Categorizing emails as spam or non-spam.</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>**Sentiment Analysis:** Classifying the sentiment of text data (positive, negative, neutral).</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>**Image Recognition:** Categorizing images into various classes like animals, objects, etc.</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>Credit Scoring: Assessing creditworthiness as high-risk or low-risk.</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>Once trained, the algorithm can classify new, unseen data by assessing its similarity to the patterns it has learned. It predicts the likelihood of the new data point falling into one of the predefined categories. This process is akin to your email provider recognizing whether an incoming email is spam or not based on past experiences.</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification Algorithms</span></span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Logistic Regression:**</span></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>Overview: Logistic Regression is used for binary classification problems. It models the probability that each input belongs to a particular category.</span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>Mechanism: This algorithm uses a logistic function to squeeze the output of a linear equation between 0 and 1. The result is the probability that the given input point belongs to a certain class.</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a><span class="al">![Image Source: &lt;https://editor.analyticsvidhya.com/uploads/82109Webp.net-resize.jpg&gt;](82109Webp.net-resize.jpg)</span></span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a>Pros:</span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a>Simple and efficient.</span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a>Provides a probability score for observations.</span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>Low variance, avoiding overfitting.</span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>Cons:</span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a>Struggles with non-linear data.</span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>Assumes no missing values and that predictors are independent.</span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>Applications: Commonly used in fields like credit scoring, medical fields for disease diagnosis, and predictive analytics.</span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Naive Bayes:**</span></span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>Overview: Based on Bayes' Theorem, it assumes independence among predictors.</span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a>Mechanism: It calculates the probability of each class and the conditional probability of each class given each input value. These probabilities are then used to classify the data.</span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a><span class="al">![Image Source: &lt;https://av-eks-blogoptimized.s3.amazonaws.com/Bayes_rule-300x172-300x172-111664.png&gt;](Bayes_rule-300x172-300x172-111664.png)</span></span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a>Pros:</span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a>Fast and efficient.</span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>Performs well with a smaller amount of data.</span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a>Handles multi-class prediction problems well.</span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-85"><a href="#cb35-85" aria-hidden="true" tabindex="-1"></a>Cons:</span>
<span id="cb35-86"><a href="#cb35-86" aria-hidden="true" tabindex="-1"></a>The assumption of independent features is often unrealistic.</span>
<span id="cb35-87"><a href="#cb35-87" aria-hidden="true" tabindex="-1"></a>Can be outperformed by more complex models.</span>
<span id="cb35-88"><a href="#cb35-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-89"><a href="#cb35-89" aria-hidden="true" tabindex="-1"></a>Applications: Widely used in spam filtering, text analysis, and sentiment analysis.</span>
<span id="cb35-90"><a href="#cb35-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-91"><a href="#cb35-91" aria-hidden="true" tabindex="-1"></a><span class="fu">### **K-Nearest Neighbors (KNN):**</span></span>
<span id="cb35-92"><a href="#cb35-92" aria-hidden="true" tabindex="-1"></a>Overview: A non-parametric method used for classification and regression.</span>
<span id="cb35-93"><a href="#cb35-93" aria-hidden="true" tabindex="-1"></a>Mechanism: Classifies data based on how its neighbors are classified. It finds the K nearest points to the new data point and classifies it based on the majority class of these points.</span>
<span id="cb35-94"><a href="#cb35-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-95"><a href="#cb35-95" aria-hidden="true" tabindex="-1"></a><span class="al">![Image Source: &lt;https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png&gt;](k-nearest-neighbor-algorithm-for-machine-learning2.png)</span></span>
<span id="cb35-96"><a href="#cb35-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-97"><a href="#cb35-97" aria-hidden="true" tabindex="-1"></a>Pros:</span>
<span id="cb35-98"><a href="#cb35-98" aria-hidden="true" tabindex="-1"></a>Simple and intuitive.</span>
<span id="cb35-99"><a href="#cb35-99" aria-hidden="true" tabindex="-1"></a>No need to build a model or tune parameters.</span>
<span id="cb35-100"><a href="#cb35-100" aria-hidden="true" tabindex="-1"></a>Flexible to feature/distance choices.</span>
<span id="cb35-101"><a href="#cb35-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-102"><a href="#cb35-102" aria-hidden="true" tabindex="-1"></a>Cons:</span>
<span id="cb35-103"><a href="#cb35-103" aria-hidden="true" tabindex="-1"></a>Slows significantly as data size increases.</span>
<span id="cb35-104"><a href="#cb35-104" aria-hidden="true" tabindex="-1"></a>Sensitive to irrelevant or redundant features.</span>
<span id="cb35-105"><a href="#cb35-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-106"><a href="#cb35-106" aria-hidden="true" tabindex="-1"></a>Applications: Used in recommendation systems, image recognition, and more.</span>
<span id="cb35-107"><a href="#cb35-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-108"><a href="#cb35-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-109"><a href="#cb35-109" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Support Vector Machine (SVM):**</span></span>
<span id="cb35-110"><a href="#cb35-110" aria-hidden="true" tabindex="-1"></a>Overview: Effective in high dimensional spaces and best suited for binary classification.</span>
<span id="cb35-111"><a href="#cb35-111" aria-hidden="true" tabindex="-1"></a>Mechanism: Constructs a hyperplane in a multidimensional space to separate different classes. SVM finds the best margin (distance between the line and the support vectors) to separate the classes.</span>
<span id="cb35-112"><a href="#cb35-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-113"><a href="#cb35-113" aria-hidden="true" tabindex="-1"></a><span class="al">![Image Source: &lt;https://static.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm5.png&gt;](support-vector-machine-algorithm5.png)</span></span>
<span id="cb35-114"><a href="#cb35-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-115"><a href="#cb35-115" aria-hidden="true" tabindex="-1"></a>Pros:</span>
<span id="cb35-116"><a href="#cb35-116" aria-hidden="true" tabindex="-1"></a>Effective in high-dimensional spaces.</span>
<span id="cb35-117"><a href="#cb35-117" aria-hidden="true" tabindex="-1"></a>Uses a subset of training points (support vectors), so it's memory efficient.</span>
<span id="cb35-118"><a href="#cb35-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-119"><a href="#cb35-119" aria-hidden="true" tabindex="-1"></a>Cons:</span>
<span id="cb35-120"><a href="#cb35-120" aria-hidden="true" tabindex="-1"></a>Not suitable for larger datasets.</span>
<span id="cb35-121"><a href="#cb35-121" aria-hidden="true" tabindex="-1"></a>Does not perform well with noisy data.</span>
<span id="cb35-122"><a href="#cb35-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-123"><a href="#cb35-123" aria-hidden="true" tabindex="-1"></a>Applications: Used in face detection, text and hypertext categorization, classification of images.</span>
<span id="cb35-124"><a href="#cb35-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-125"><a href="#cb35-125" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Decision Tree:**</span></span>
<span id="cb35-126"><a href="#cb35-126" aria-hidden="true" tabindex="-1"></a>Overview: A tree-structure algorithm, where each node represents a feature, each branch a decision rule, and each leaf a class.</span>
<span id="cb35-127"><a href="#cb35-127" aria-hidden="true" tabindex="-1"></a>Mechanism: Splits the data into subsets based on feature values. This process is repeated recursively, resulting in a tree with decision nodes and leaf nodes.</span>
<span id="cb35-128"><a href="#cb35-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-129"><a href="#cb35-129" aria-hidden="true" tabindex="-1"></a><span class="al">![Image Source: &lt;https://lh4.googleusercontent.com/v9UQUwaQTAXVH90b-Ugyw2_61_uErfYvTBtG-RNRNB_eHUFq9AmAN_2IOdfOETnbXImnQVN-wPC7_YzDgf7urCeyhyx5UZmuSwV8BVsV8VnHxl1KtgpuxDifJ4pLE23ooYXLlnc&gt;](dig10.PNG)</span></span>
<span id="cb35-130"><a href="#cb35-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-131"><a href="#cb35-131" aria-hidden="true" tabindex="-1"></a>Pros:</span>
<span id="cb35-132"><a href="#cb35-132" aria-hidden="true" tabindex="-1"></a>Easy to interpret and explain.</span>
<span id="cb35-133"><a href="#cb35-133" aria-hidden="true" tabindex="-1"></a>Requires little data preparation.</span>
<span id="cb35-134"><a href="#cb35-134" aria-hidden="true" tabindex="-1"></a>Can handle both numerical and categorical data.</span>
<span id="cb35-135"><a href="#cb35-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-136"><a href="#cb35-136" aria-hidden="true" tabindex="-1"></a>Cons:</span>
<span id="cb35-137"><a href="#cb35-137" aria-hidden="true" tabindex="-1"></a>Prone to overfitting, especially with complex trees.</span>
<span id="cb35-138"><a href="#cb35-138" aria-hidden="true" tabindex="-1"></a>Small changes in data can lead to a different tree.</span>
<span id="cb35-139"><a href="#cb35-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-140"><a href="#cb35-140" aria-hidden="true" tabindex="-1"></a>Applications: Used in customer segmentation, fraud detection, and risk assessment.</span>
<span id="cb35-141"><a href="#cb35-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-142"><a href="#cb35-142" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example: Credit Card Fraud Detection</span></span>
<span id="cb35-143"><a href="#cb35-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-146"><a href="#cb35-146" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-147"><a href="#cb35-147" aria-hidden="true" tabindex="-1"></a><span class="co">#Importing librairies</span></span>
<span id="cb35-148"><a href="#cb35-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-149"><a href="#cb35-149" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb35-150"><a href="#cb35-150" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-151"><a href="#cb35-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-152"><a href="#cb35-152" aria-hidden="true" tabindex="-1"></a><span class="co"># Scikit-learn library: For SVM</span></span>
<span id="cb35-153"><a href="#cb35-153" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb35-154"><a href="#cb35-154" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb35-155"><a href="#cb35-155" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb35-156"><a href="#cb35-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-157"><a href="#cb35-157" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb35-158"><a href="#cb35-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-159"><a href="#cb35-159" aria-hidden="true" tabindex="-1"></a><span class="co"># Matplotlib library to plot the charts</span></span>
<span id="cb35-160"><a href="#cb35-160" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb35-161"><a href="#cb35-161" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.mlab <span class="im">as</span> mlab</span>
<span id="cb35-162"><a href="#cb35-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-163"><a href="#cb35-163" aria-hidden="true" tabindex="-1"></a><span class="co"># Library for the statistic data vizualisation</span></span>
<span id="cb35-164"><a href="#cb35-164" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn</span>
<span id="cb35-165"><a href="#cb35-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-166"><a href="#cb35-166" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb35-167"><a href="#cb35-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-168"><a href="#cb35-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-169"><a href="#cb35-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-170"><a href="#cb35-170" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-171"><a href="#cb35-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-172"><a href="#cb35-172" aria-hidden="true" tabindex="-1"></a>**Data recuperation**</span>
<span id="cb35-173"><a href="#cb35-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-176"><a href="#cb35-176" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-177"><a href="#cb35-177" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'R:/Blog/posts/classification/creditcard.csv'</span>) <span class="co"># Reading the file .csv</span></span>
<span id="cb35-178"><a href="#cb35-178" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data) <span class="co"># Converting data to Panda DataFrame</span></span>
<span id="cb35-179"><a href="#cb35-179" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-180"><a href="#cb35-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-181"><a href="#cb35-181" aria-hidden="true" tabindex="-1"></a>**Data Visualization**</span>
<span id="cb35-182"><a href="#cb35-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-185"><a href="#cb35-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-186"><a href="#cb35-186" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data) <span class="co"># Converting data to Panda DataFrame</span></span>
<span id="cb35-187"><a href="#cb35-187" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-188"><a href="#cb35-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-191"><a href="#cb35-191" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-192"><a href="#cb35-192" aria-hidden="true" tabindex="-1"></a>df.describe() <span class="co"># Description of statistic features (Sum, Average, Variance, minimum, 1st quartile, 2nd quartile, 3rd Quartile and Maximum)</span></span>
<span id="cb35-193"><a href="#cb35-193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-194"><a href="#cb35-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-195"><a href="#cb35-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-198"><a href="#cb35-198" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-199"><a href="#cb35-199" aria-hidden="true" tabindex="-1"></a>df_fraud <span class="op">=</span> df[df[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">1</span>] <span class="co"># Recovery of fraud data</span></span>
<span id="cb35-200"><a href="#cb35-200" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb35-201"><a href="#cb35-201" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_fraud[<span class="st">'Time'</span>], df_fraud[<span class="st">'Amount'</span>]) <span class="co"># Display fraud amounts according to their time</span></span>
<span id="cb35-202"><a href="#cb35-202" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Scratter plot amount fraud'</span>)</span>
<span id="cb35-203"><a href="#cb35-203" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time'</span>)</span>
<span id="cb35-204"><a href="#cb35-204" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Amount'</span>)</span>
<span id="cb35-205"><a href="#cb35-205" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="dv">0</span>,<span class="dv">175000</span>])</span>
<span id="cb35-206"><a href="#cb35-206" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="dv">0</span>,<span class="dv">2500</span>])</span>
<span id="cb35-207"><a href="#cb35-207" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-208"><a href="#cb35-208" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-209"><a href="#cb35-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-212"><a href="#cb35-212" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-213"><a href="#cb35-213" aria-hidden="true" tabindex="-1"></a>nb_big_fraud <span class="op">=</span> df_fraud[df_fraud[<span class="st">'Amount'</span>] <span class="op">&gt;</span> <span class="dv">1000</span>].shape[<span class="dv">0</span>] <span class="co"># Recovery of frauds over 1000</span></span>
<span id="cb35-214"><a href="#cb35-214" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'There are only '</span><span class="op">+</span> <span class="bu">str</span>(nb_big_fraud) <span class="op">+</span> <span class="st">' frauds where the amount was bigger than 1000 over '</span> <span class="op">+</span> <span class="bu">str</span>(df_fraud.shape[<span class="dv">0</span>]) <span class="op">+</span> <span class="st">' frauds'</span>)</span>
<span id="cb35-215"><a href="#cb35-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-216"><a href="#cb35-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-217"><a href="#cb35-217" aria-hidden="true" tabindex="-1"></a>There are only 9 frauds where the amount was bigger than 1000 over 492 frauds</span>
<span id="cb35-218"><a href="#cb35-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-219"><a href="#cb35-219" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Unbalanced data</span>
<span id="cb35-220"><a href="#cb35-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-223"><a href="#cb35-223" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-224"><a href="#cb35-224" aria-hidden="true" tabindex="-1"></a>number_fraud <span class="op">=</span> <span class="bu">len</span>(data[data.Class <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb35-225"><a href="#cb35-225" aria-hidden="true" tabindex="-1"></a>number_no_fraud <span class="op">=</span> <span class="bu">len</span>(data[data.Class <span class="op">==</span> <span class="dv">0</span>])</span>
<span id="cb35-226"><a href="#cb35-226" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'There are only '</span><span class="op">+</span> <span class="bu">str</span>(number_fraud) <span class="op">+</span> <span class="st">' frauds in the original dataset, even though there are '</span> <span class="op">+</span> <span class="bu">str</span>(number_no_fraud) <span class="op">+</span><span class="st">' no frauds in the dataset.'</span>)</span>
<span id="cb35-227"><a href="#cb35-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-228"><a href="#cb35-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-229"><a href="#cb35-229" aria-hidden="true" tabindex="-1"></a>There are only 492 frauds in the original dataset, even though there are 284315 no frauds in the dataset.</span>
<span id="cb35-230"><a href="#cb35-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-233"><a href="#cb35-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-234"><a href="#cb35-234" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy of the classifier then would be : "</span><span class="op">+</span> <span class="bu">str</span>((<span class="dv">284315</span><span class="op">-</span><span class="dv">492</span>)<span class="op">/</span><span class="dv">284315</span>)<span class="op">+</span> <span class="st">" which is the number of good classification over the number of tuple to classify"</span>)</span>
<span id="cb35-235"><a href="#cb35-235" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-236"><a href="#cb35-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-237"><a href="#cb35-237" aria-hidden="true" tabindex="-1"></a>**Correlation of features**</span>
<span id="cb35-238"><a href="#cb35-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-241"><a href="#cb35-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-242"><a href="#cb35-242" aria-hidden="true" tabindex="-1"></a>df_corr <span class="op">=</span> df.corr() <span class="co"># Calculation of the correlation coefficients in pairs, with the default method:</span></span>
<span id="cb35-243"><a href="#cb35-243" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Pearson, Standard Correlation Coefficient</span></span>
<span id="cb35-244"><a href="#cb35-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-245"><a href="#cb35-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-248"><a href="#cb35-248" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-249"><a href="#cb35-249" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb35-250"><a href="#cb35-250" aria-hidden="true" tabindex="-1"></a>seaborn.heatmap(df_corr, cmap<span class="op">=</span><span class="st">"YlGnBu"</span>) <span class="co"># Displaying the Heatmap</span></span>
<span id="cb35-251"><a href="#cb35-251" aria-hidden="true" tabindex="-1"></a>seaborn.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="dv">2</span>,style<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb35-252"><a href="#cb35-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-253"><a href="#cb35-253" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Heatmap correlation'</span>)</span>
<span id="cb35-254"><a href="#cb35-254" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-255"><a href="#cb35-255" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-256"><a href="#cb35-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-257"><a href="#cb35-257" aria-hidden="true" tabindex="-1"></a>As we can notice, most of the features are not correlated with each other. This corroborates the fact that a PCA was previously performed on the data.</span>
<span id="cb35-258"><a href="#cb35-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-259"><a href="#cb35-259" aria-hidden="true" tabindex="-1"></a>What can generally be done on a massive dataset is a dimension reduction. By picking th emost important dimensions, there is a possiblity of explaining most of the problem, thus gaining a considerable amount of time while preventing the accuracy to drop too much.</span>
<span id="cb35-260"><a href="#cb35-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-261"><a href="#cb35-261" aria-hidden="true" tabindex="-1"></a>However in this case given the fact that a PCA was previously performed, if the dimension reduction is effective then the PCA wasn't computed in the most effective way. Another way to put it is that no dimension reduction should be computed on a dataset on which a PCA was computed correctly.</span>
<span id="cb35-262"><a href="#cb35-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-263"><a href="#cb35-263" aria-hidden="true" tabindex="-1"></a>**Correlation of features**</span>
<span id="cb35-264"><a href="#cb35-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-265"><a href="#cb35-265" aria-hidden="true" tabindex="-1"></a>OVERSAMPLING</span>
<span id="cb35-266"><a href="#cb35-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-267"><a href="#cb35-267" aria-hidden="true" tabindex="-1"></a>One way to do oversampling is to replicate the under-represented class tuples until we attain a correct proportion between the class</span>
<span id="cb35-268"><a href="#cb35-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-269"><a href="#cb35-269" aria-hidden="true" tabindex="-1"></a>However as we haven't infinite time nor the patience, we are going to run the classifier with the undersampled training data (for those using the undersampling principle if results are really bad just rerun the training dataset definition)</span>
<span id="cb35-270"><a href="#cb35-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-271"><a href="#cb35-271" aria-hidden="true" tabindex="-1"></a>UNDERSAMPLING</span>
<span id="cb35-272"><a href="#cb35-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-275"><a href="#cb35-275" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-276"><a href="#cb35-276" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-277"><a href="#cb35-277" aria-hidden="true" tabindex="-1"></a><span class="co"># We seperate ours data in two groups : a train dataset and a test dataset</span></span>
<span id="cb35-278"><a href="#cb35-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-279"><a href="#cb35-279" aria-hidden="true" tabindex="-1"></a><span class="co"># First we build our train dataset</span></span>
<span id="cb35-280"><a href="#cb35-280" aria-hidden="true" tabindex="-1"></a>df_train_all <span class="op">=</span> df[<span class="dv">0</span>:<span class="dv">150000</span>] <span class="co"># We cut in two the original dataset</span></span>
<span id="cb35-281"><a href="#cb35-281" aria-hidden="true" tabindex="-1"></a>df_train_1 <span class="op">=</span> df_train_all[df_train_all[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">1</span>] <span class="co"># We seperate the data which are the frauds and the no frauds</span></span>
<span id="cb35-282"><a href="#cb35-282" aria-hidden="true" tabindex="-1"></a>df_train_0 <span class="op">=</span> df_train_all[df_train_all[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb35-283"><a href="#cb35-283" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'In this dataset, we have '</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">len</span>(df_train_1)) <span class="op">+</span><span class="st">" frauds so we need to take a similar number of non-fraud"</span>)</span>
<span id="cb35-284"><a href="#cb35-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-285"><a href="#cb35-285" aria-hidden="true" tabindex="-1"></a>df_sample<span class="op">=</span>df_train_0.sample(<span class="dv">300</span>)</span>
<span id="cb35-286"><a href="#cb35-286" aria-hidden="true" tabindex="-1"></a>combined_df <span class="op">=</span> pd.concat([df_train_1, df_sample], ignore_index<span class="op">=</span><span class="va">True</span>) <span class="co"># We gather the frauds with the no frauds. </span></span>
<span id="cb35-287"><a href="#cb35-287" aria-hidden="true" tabindex="-1"></a>combined_df <span class="op">=</span> combined_df.sample(frac<span class="op">=</span><span class="dv">1</span>) <span class="co"># Then we mix our dataset</span></span>
<span id="cb35-288"><a href="#cb35-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-289"><a href="#cb35-289" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-290"><a href="#cb35-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-291"><a href="#cb35-291" aria-hidden="true" tabindex="-1"></a>In this dataset, we have 293 frauds so we need to take a similar number of non-fraud</span>
<span id="cb35-292"><a href="#cb35-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-295"><a href="#cb35-295" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-296"><a href="#cb35-296" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> combined_df.drop([<span class="st">'Time'</span>, <span class="st">'Class'</span>], axis<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Drop the features "Time" (useless) and "Class" (label)</span></span>
<span id="cb35-297"><a href="#cb35-297" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> combined_df[<span class="st">'Class'</span>]  <span class="co"># Create the label</span></span>
<span id="cb35-298"><a href="#cb35-298" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.asarray(X_train)</span>
<span id="cb35-299"><a href="#cb35-299" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.asarray(y_train)</span>
<span id="cb35-300"><a href="#cb35-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-301"><a href="#cb35-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-304"><a href="#cb35-304" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-305"><a href="#cb35-305" aria-hidden="true" tabindex="-1"></a><span class="co">############################## with all the test dataset to see if the model learn correctly ##################</span></span>
<span id="cb35-306"><a href="#cb35-306" aria-hidden="true" tabindex="-1"></a>df_test_all <span class="op">=</span> df[<span class="dv">150000</span>:]</span>
<span id="cb35-307"><a href="#cb35-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-308"><a href="#cb35-308" aria-hidden="true" tabindex="-1"></a>X_test_all <span class="op">=</span> df_test_all.drop([<span class="st">'Time'</span>, <span class="st">'Class'</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-309"><a href="#cb35-309" aria-hidden="true" tabindex="-1"></a>y_test_all <span class="op">=</span> df_test_all[<span class="st">'Class'</span>]</span>
<span id="cb35-310"><a href="#cb35-310" aria-hidden="true" tabindex="-1"></a>X_test_all <span class="op">=</span> np.asarray(X_test_all)</span>
<span id="cb35-311"><a href="#cb35-311" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-312"><a href="#cb35-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-313"><a href="#cb35-313" aria-hidden="true" tabindex="-1"></a>**Confusion Matrix**</span>
<span id="cb35-314"><a href="#cb35-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-317"><a href="#cb35-317" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-318"><a href="#cb35-318" aria-hidden="true" tabindex="-1"></a>class_names<span class="op">=</span>np.array([<span class="st">'0'</span>,<span class="st">'1'</span>]) <span class="co"># Binary label, Class = 1 (fraud) and Class = 0 (no fraud)</span></span>
<span id="cb35-319"><a href="#cb35-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-320"><a href="#cb35-320" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-321"><a href="#cb35-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-324"><a href="#cb35-324" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-325"><a href="#cb35-325" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to plot the confusion Matrix</span></span>
<span id="cb35-326"><a href="#cb35-326" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(cm, classes,</span>
<span id="cb35-327"><a href="#cb35-327" aria-hidden="true" tabindex="-1"></a>                          title<span class="op">=</span><span class="st">'Confusion matrix'</span>,</span>
<span id="cb35-328"><a href="#cb35-328" aria-hidden="true" tabindex="-1"></a>                          cmap<span class="op">=</span>plt.cm.Blues):</span>
<span id="cb35-329"><a href="#cb35-329" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-330"><a href="#cb35-330" aria-hidden="true" tabindex="-1"></a>    plt.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span>cmap)</span>
<span id="cb35-331"><a href="#cb35-331" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb35-332"><a href="#cb35-332" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb35-333"><a href="#cb35-333" aria-hidden="true" tabindex="-1"></a>    tick_marks <span class="op">=</span> np.arange(<span class="bu">len</span>(classes))</span>
<span id="cb35-334"><a href="#cb35-334" aria-hidden="true" tabindex="-1"></a>    plt.xticks(tick_marks, classes, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb35-335"><a href="#cb35-335" aria-hidden="true" tabindex="-1"></a>    plt.yticks(tick_marks, classes)</span>
<span id="cb35-336"><a href="#cb35-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-337"><a href="#cb35-337" aria-hidden="true" tabindex="-1"></a>    fmt <span class="op">=</span> <span class="st">'d'</span> </span>
<span id="cb35-338"><a href="#cb35-338" aria-hidden="true" tabindex="-1"></a>    thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="fl">2.</span></span>
<span id="cb35-339"><a href="#cb35-339" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, j <span class="kw">in</span> itertools.product(<span class="bu">range</span>(cm.shape[<span class="dv">0</span>]), <span class="bu">range</span>(cm.shape[<span class="dv">1</span>])):</span>
<span id="cb35-340"><a href="#cb35-340" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, <span class="bu">format</span>(cm[i, j], fmt),</span>
<span id="cb35-341"><a href="#cb35-341" aria-hidden="true" tabindex="-1"></a>                 horizontalalignment<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb35-342"><a href="#cb35-342" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">"white"</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span>)</span>
<span id="cb35-343"><a href="#cb35-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-344"><a href="#cb35-344" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb35-345"><a href="#cb35-345" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'True label'</span>)</span>
<span id="cb35-346"><a href="#cb35-346" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Predicted label'</span>)</span>
<span id="cb35-347"><a href="#cb35-347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-348"><a href="#cb35-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-349"><a href="#cb35-349" aria-hidden="true" tabindex="-1"></a>**Model Selection**</span>
<span id="cb35-350"><a href="#cb35-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-351"><a href="#cb35-351" aria-hidden="true" tabindex="-1"></a>So now, we'll use a SVM model classifier, with the scikit-learn library.</span>
<span id="cb35-352"><a href="#cb35-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-355"><a href="#cb35-355" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-356"><a href="#cb35-356" aria-hidden="true" tabindex="-1"></a>classifier <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'linear'</span>) <span class="co"># We set a SVM classifier, the default SVM Classifier (Kernel = Radial Basis Function)</span></span>
<span id="cb35-357"><a href="#cb35-357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-358"><a href="#cb35-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-361"><a href="#cb35-361" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-362"><a href="#cb35-362" aria-hidden="true" tabindex="-1"></a>classifier.fit(X_train, y_train) <span class="co"># Then we train our model, with our balanced data train.</span></span>
<span id="cb35-363"><a href="#cb35-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-364"><a href="#cb35-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-365"><a href="#cb35-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-366"><a href="#cb35-366" aria-hidden="true" tabindex="-1"></a>**Testing the model**</span>
<span id="cb35-367"><a href="#cb35-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-368"><a href="#cb35-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-371"><a href="#cb35-371" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-372"><a href="#cb35-372" aria-hidden="true" tabindex="-1"></a>prediction_SVM_all <span class="op">=</span> classifier.predict(X_test_all) <span class="co">#And finally, we predict our data test.</span></span>
<span id="cb35-373"><a href="#cb35-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-374"><a href="#cb35-374" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-375"><a href="#cb35-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-378"><a href="#cb35-378" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-379"><a href="#cb35-379" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_all, prediction_SVM_all)</span>
<span id="cb35-380"><a href="#cb35-380" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(cm,class_names)</span>
<span id="cb35-381"><a href="#cb35-381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-382"><a href="#cb35-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-383"><a href="#cb35-383" aria-hidden="true" tabindex="-1"></a>In this case we are gonna try to minimize the number of errors in our prediction results. Errors are on the anti-diagonal of the confusion matrix. But we can infer that being wrong about an actual fraud is far worse than being wrong about a non-fraud transaction.</span>
<span id="cb35-384"><a href="#cb35-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-385"><a href="#cb35-385" aria-hidden="true" tabindex="-1"></a>That is why using the accuracy as only classification criterion could be considered unthoughtful. During the remaining part of this study our criterion will consider precision on the real fraud 4 times more important than the general accuracy. Even though the final tested result is accuracy.</span>
<span id="cb35-386"><a href="#cb35-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-389"><a href="#cb35-389" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-390"><a href="#cb35-390" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Our criterion give a result of '</span> </span>
<span id="cb35-391"><a href="#cb35-391" aria-hidden="true" tabindex="-1"></a>      <span class="op">+</span> <span class="bu">str</span>( ( (cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>])) <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>])) <span class="op">/</span> <span class="dv">5</span>))</span>
<span id="cb35-392"><a href="#cb35-392" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-393"><a href="#cb35-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-394"><a href="#cb35-394" aria-hidden="true" tabindex="-1"></a>Our criterion give a result of 0.905383035408</span>
<span id="cb35-395"><a href="#cb35-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-398"><a href="#cb35-398" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-399"><a href="#cb35-399" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'We have detected '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">+</span> <span class="st">' frauds / '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>]) <span class="op">+</span> <span class="st">' total frauds.'</span>)</span>
<span id="cb35-400"><a href="#cb35-400" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">So, the probability to detect a fraud is '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>])))</span>
<span id="cb35-401"><a href="#cb35-401" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"the accuracy is : "</span><span class="op">+</span><span class="bu">str</span>((cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>]))))</span>
<span id="cb35-402"><a href="#cb35-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-403"><a href="#cb35-403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-404"><a href="#cb35-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-405"><a href="#cb35-405" aria-hidden="true" tabindex="-1"></a>We have detected 177 frauds / 199 total frauds.</span>
<span id="cb35-406"><a href="#cb35-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-407"><a href="#cb35-407" aria-hidden="true" tabindex="-1"></a>So, the probability to detect a fraud is 0.889447236181</span>
<span id="cb35-408"><a href="#cb35-408" aria-hidden="true" tabindex="-1"></a>the accuracy is : 0.969126232317</span>
<span id="cb35-409"><a href="#cb35-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-410"><a href="#cb35-410" aria-hidden="true" tabindex="-1"></a>**Models Rank**</span>
<span id="cb35-411"><a href="#cb35-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-412"><a href="#cb35-412" aria-hidden="true" tabindex="-1"></a>There is a need to compute the fit method again, as the dimension of the tuples to predict went from 29 to 10 because of the dimension reduction</span>
<span id="cb35-413"><a href="#cb35-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-414"><a href="#cb35-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-415"><a href="#cb35-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-418"><a href="#cb35-418" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-419"><a href="#cb35-419" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a simple feature ranking function (you can customize this)</span></span>
<span id="cb35-420"><a href="#cb35-420" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rank_features(data):</span>
<span id="cb35-421"><a href="#cb35-421" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement your feature ranking logic here</span></span>
<span id="cb35-422"><a href="#cb35-422" aria-hidden="true" tabindex="-1"></a>    ranked_features <span class="op">=</span> data  <span class="co"># Replace this with your actual feature ranking code</span></span>
<span id="cb35-423"><a href="#cb35-423" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ranked_features</span>
<span id="cb35-424"><a href="#cb35-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-425"><a href="#cb35-425" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can use the rank_features function</span></span>
<span id="cb35-426"><a href="#cb35-426" aria-hidden="true" tabindex="-1"></a>X_train_rank <span class="op">=</span> rank_features(X_train)</span>
<span id="cb35-427"><a href="#cb35-427" aria-hidden="true" tabindex="-1"></a>X_test_all_rank <span class="op">=</span> rank_features(X_test_all)</span>
<span id="cb35-428"><a href="#cb35-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-429"><a href="#cb35-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-430"><a href="#cb35-430" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-431"><a href="#cb35-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-434"><a href="#cb35-434" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-435"><a href="#cb35-435" aria-hidden="true" tabindex="-1"></a>prediction_SVM <span class="op">=</span> classifier.predict(X_test_all_rank)</span>
<span id="cb35-436"><a href="#cb35-436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-437"><a href="#cb35-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-440"><a href="#cb35-440" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-441"><a href="#cb35-441" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_all, prediction_SVM)</span>
<span id="cb35-442"><a href="#cb35-442" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(cm,class_names)</span>
<span id="cb35-443"><a href="#cb35-443" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-446"><a href="#cb35-446" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-447"><a href="#cb35-447" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Our criterion give a result of '</span> </span>
<span id="cb35-448"><a href="#cb35-448" aria-hidden="true" tabindex="-1"></a>      <span class="op">+</span> <span class="bu">str</span>( ( (cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>])) <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>])) <span class="op">/</span> <span class="dv">5</span>))</span>
<span id="cb35-449"><a href="#cb35-449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-450"><a href="#cb35-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-451"><a href="#cb35-451" aria-hidden="true" tabindex="-1"></a>Our criterion give a result of 0.912995958898</span>
<span id="cb35-452"><a href="#cb35-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-455"><a href="#cb35-455" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb35-456"><a href="#cb35-456" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'We have detected '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">+</span> <span class="st">' frauds / '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>]) <span class="op">+</span> <span class="st">' total frauds.'</span>)</span>
<span id="cb35-457"><a href="#cb35-457" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">So, the probability to detect a fraud is '</span> <span class="op">+</span> <span class="bu">str</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>(cm[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">0</span>])))</span>
<span id="cb35-458"><a href="#cb35-458" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"the accuracy is : "</span><span class="op">+</span><span class="bu">str</span>((cm[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">+</span>cm[<span class="dv">1</span>][<span class="dv">1</span>]) <span class="op">/</span> (<span class="bu">sum</span>(cm[<span class="dv">0</span>]) <span class="op">+</span> <span class="bu">sum</span>(cm[<span class="dv">1</span>]))))</span>
<span id="cb35-459"><a href="#cb35-459" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-460"><a href="#cb35-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-461"><a href="#cb35-461" aria-hidden="true" tabindex="-1"></a>We have detected 179 frauds / 199 total frauds.</span>
<span id="cb35-462"><a href="#cb35-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-463"><a href="#cb35-463" aria-hidden="true" tabindex="-1"></a>So, the probability to detect a fraud is 0.899497487437</span>
<span id="cb35-464"><a href="#cb35-464" aria-hidden="true" tabindex="-1"></a>the accuracy is : 0.966989844741</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>